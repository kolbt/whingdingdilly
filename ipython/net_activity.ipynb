{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are my rc parameters for matplotlib\n",
    "mpl.rc('font', serif='Helvetica Neue') \n",
    "mpl.rcParams.update({'font.size': 9})\n",
    "mpl.rcParams['figure.figsize'] = 3.2, 2.8\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "mpl.rcParams['xtick.direction'] = 'in'\n",
    "mpl.rcParams['ytick.direction'] = 'in'\n",
    "mpl.rcParams['lines.linewidth'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(name):\n",
    "    home = os.path.expanduser(\"~\")\n",
    "    for root, dirs, files in os.walk(home):\n",
    "        if name in dirs:\n",
    "            return os.path.join(root, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's find all of our data\n",
    "whingPath = find('whingdingdilly')\n",
    "ipyPath = whingPath + '/ipython'\n",
    "dataPath = ipyPath + '/all_data'\n",
    "\n",
    "# Go to the correct parent directory\n",
    "os.chdir(ipyPath)\n",
    "txtFiles = os.listdir(dataPath)\n",
    "numFiles = len(txtFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to sort my data with\n",
    "def getFromTxt(fname, first, last):\n",
    "    \"\"\"Takes a string, text before and after desired text, outs text between\"\"\"\n",
    "    start = fname.index( first ) + len( first )\n",
    "    end = fname.index( last, start )\n",
    "    myTxt = fname[start:end]\n",
    "    return float(myTxt)\n",
    "        \n",
    "def multiSort(arr1, arr2, arr3):\n",
    "    \"\"\"Sort an array the slow (but certain) way, returns original indices in sorted order\"\"\"\n",
    "    # Doing this for PeR, PeS, xS in this case\n",
    "    cpy1 = np.copy(arr1)\n",
    "    cpy2 = np.copy(arr2)\n",
    "    cpy3 = np.copy(arr3)\n",
    "    ind = np.arange(0, len(arr1))\n",
    "    for i in xrange(len(cpy1)):\n",
    "        for j in xrange(len(cpy1)):\n",
    "            # Sort by first variable\n",
    "            if cpy1[i] > cpy1[j] and i < j:\n",
    "                # Swap copy array values\n",
    "                cpy1[i], cpy1[j] = cpy1[j], cpy1[i]\n",
    "                cpy2[i], cpy2[j] = cpy2[j], cpy2[i]\n",
    "                cpy3[i], cpy3[j] = cpy3[j], cpy3[i]\n",
    "                # Swap the corresponding indices\n",
    "                ind[i], ind[j] = ind[j], ind[i]\n",
    "                \n",
    "            # If first variable is equal, resort to second variable\n",
    "            elif cpy1[i] == cpy1[j] and cpy2[i] > cpy2[j] and i < j:\n",
    "                # Swap copy array values\n",
    "                cpy1[i], cpy1[j] = cpy1[j], cpy1[i]\n",
    "                cpy2[i], cpy2[j] = cpy2[j], cpy2[i]\n",
    "                cpy3[i], cpy3[j] = cpy3[j], cpy3[i]\n",
    "                # Swap the corresponding indices\n",
    "                ind[i], ind[j] = ind[j], ind[i]\n",
    "                \n",
    "            elif cpy1[i] == cpy1[j] and cpy2[i] == cpy2[j] and cpy3[i] > cpy3[j] and i < j:\n",
    "                # Swap copy array values\n",
    "                cpy1[i], cpy1[j] = cpy1[j], cpy1[i]\n",
    "                cpy2[i], cpy2[j] = cpy2[j], cpy2[i]\n",
    "                cpy3[i], cpy3[j] = cpy3[j], cpy3[i]\n",
    "                # Swap the corresponding indices\n",
    "                ind[i], ind[j] = ind[j], ind[i]      \n",
    "    return ind\n",
    "\n",
    "def indSort(arr1, arr2):\n",
    "    \"\"\"Take sorted index array, use to sort array\"\"\"\n",
    "    # arr1 is array to sort\n",
    "    # arr2 is index array\n",
    "    cpy = np.copy(arr1)\n",
    "    for i in xrange(len(arr1)):\n",
    "        arr1[i] = cpy[arr2[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You want to load the data in so that it's sorted to begin with\n",
    "paList = []\n",
    "pbList = []\n",
    "prList = []\n",
    "xaList = []\n",
    "for i in xrange(numFiles):\n",
    "    paList.append(getFromTxt(txtFiles[i], \"pa\", \"_pb\"))\n",
    "    pbList.append(getFromTxt(txtFiles[i], \"pb\", \"_xa\"))\n",
    "    xaList.append(getFromTxt(txtFiles[i], \"xa\", \"_ep\"))\n",
    "    # We want to use ratios rounded to nearest 0.05\n",
    "    tmpPeR = round(paList[i]/pbList[i] * 2, 1) / 2\n",
    "    prList.append(tmpPeR)\n",
    "    \n",
    "# Now sort the array of txtFile names\n",
    "indArr = multiSort(prList, paList, xaList)\n",
    "indSort(txtFiles, indArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data in pandas dataframes\n",
    "all_sims = []\n",
    "os.chdir(dataPath)\n",
    "for i in xrange(numFiles):\n",
    "    df = pd.read_csv(txtFiles[i], sep='\\s+', header=0)\n",
    "    all_sims.append(df)\n",
    "    \n",
    "# Return to root directory\n",
    "os.chdir(ipyPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diam_pa0_pb500_xa10_ep82.txt sorted... \n",
      "diam_pa0_pb500_xa20_ep82.txt sorted... \n",
      "diam_pa0_pb500_xa30_ep82.txt sorted... \n",
      "diam_pa0_pb500_xa40_ep82.txt sorted... \n",
      "diam_pa0_pb500_xa50_ep82.txt sorted... \n",
      "diam_pa0_pb500_xa60_ep82.txt sorted... \n",
      "diam_pa0_pb500_xa70_ep82.txt sorted... \n",
      "diam_pa0_pb500_xa80_ep82.txt sorted... \n",
      "diam_pa0_pb500_xa90_ep82.txt sorted... \n",
      "diam_pa10_pb100_xa50_ep18.txt sorted... \n",
      "diam_pa20_pb200_xa50_ep34.txt sorted... \n",
      "diam_pa30_pb300_xa50_ep50.txt sorted... \n",
      "diam_pa40_pb400_xa50_ep66.txt sorted... \n",
      "diam_pa50_pb500_xa50_ep82.txt sorted... \n",
      "diam_pa60_pb600_xa50_ep98.txt sorted... \n",
      "diam_pa70_pb700_xa50_ep114.txt sorted... \n",
      "diam_pa80_pb800_xa50_ep130.txt sorted... \n",
      "diam_pa90_pb900_xa50_ep146.txt sorted... \n",
      "diam_pa100_pb1000_xa50_ep162.txt sorted... \n",
      "diam_pa110_pb1100_xa50_ep178.txt sorted... \n",
      "diam_pa120_pb1200_xa50_ep194.txt sorted... \n",
      "diam_pa130_pb1300_xa50_ep210.txt sorted... \n",
      "diam_pa140_pb1400_xa50_ep226.txt sorted... \n",
      "diam_pa150_pb1500_xa50_ep242.txt sorted... \n",
      "diam_pa100_pb500_xa50_ep82.txt sorted... \n",
      "diam_pa125_pb500_xa10_ep82.txt sorted... \n",
      "diam_pa125_pb500_xa20_ep82.txt sorted... \n",
      "diam_pa125_pb500_xa30_ep82.txt sorted... \n",
      "diam_pa125_pb500_xa40_ep82.txt sorted... \n",
      "diam_pa125_pb500_xa50_ep82.txt sorted... \n",
      "diam_pa125_pb500_xa60_ep82.txt sorted... \n",
      "diam_pa125_pb500_xa70_ep82.txt sorted... \n",
      "diam_pa125_pb500_xa80_ep82.txt sorted... \n",
      "diam_pa125_pb500_xa90_ep82.txt sorted... \n",
      "diam_pa125_pb500_xa100_ep82.txt sorted... \n",
      "diam_pa10_pb33_xa30_ep7.txt sorted... \n",
      "diam_pa10_pb33_xa50_ep7.txt sorted... \n",
      "diam_pa10_pb33_xa70_ep7.txt sorted... \n",
      "diam_pa20_pb66_xa30_ep12.txt sorted... \n",
      "diam_pa20_pb66_xa50_ep12.txt sorted... \n",
      "diam_pa20_pb66_xa70_ep12.txt sorted... \n",
      "diam_pa30_pb100_xa30_ep18.txt sorted... \n",
      "diam_pa30_pb100_xa50_ep18.txt sorted... \n",
      "diam_pa30_pb100_xa70_ep18.txt sorted... \n",
      "diam_pa40_pb133_xa30_ep23.txt sorted... \n",
      "diam_pa40_pb133_xa50_ep23.txt sorted... \n",
      "diam_pa40_pb133_xa70_ep23.txt sorted... \n",
      "diam_pa50_pb166_xa30_ep28.txt sorted... \n",
      "diam_pa50_pb166_xa50_ep28.txt sorted... \n",
      "diam_pa50_pb166_xa70_ep28.txt sorted... \n",
      "diam_pa60_pb200_xa30_ep34.txt sorted... \n",
      "diam_pa60_pb200_xa50_ep34.txt sorted... \n",
      "diam_pa60_pb200_xa70_ep34.txt sorted... \n",
      "diam_pa70_pb233_xa30_ep39.txt sorted... \n",
      "diam_pa70_pb233_xa50_ep39.txt sorted... \n",
      "diam_pa70_pb233_xa70_ep39.txt sorted... \n",
      "diam_pa80_pb266_xa30_ep44.txt sorted... \n",
      "diam_pa80_pb266_xa50_ep44.txt sorted... \n",
      "diam_pa80_pb266_xa70_ep44.txt sorted... \n",
      "diam_pa90_pb300_xa30_ep50.txt sorted... \n",
      "diam_pa90_pb300_xa50_ep50.txt sorted... \n",
      "diam_pa90_pb300_xa70_ep50.txt sorted... \n",
      "diam_pa100_pb333_xa30_ep55.txt sorted... \n",
      "diam_pa100_pb333_xa50_ep55.txt sorted... \n",
      "diam_pa100_pb333_xa70_ep55.txt sorted... \n",
      "diam_pa110_pb366_xa30_ep60.txt sorted... \n",
      "diam_pa110_pb366_xa50_ep60.txt sorted... \n",
      "diam_pa110_pb366_xa70_ep60.txt sorted... \n",
      "diam_pa120_pb400_xa30_ep66.txt sorted... \n",
      "diam_pa120_pb400_xa50_ep66.txt sorted... \n",
      "diam_pa120_pb400_xa70_ep66.txt sorted... \n",
      "diam_pa130_pb433_xa30_ep71.txt sorted... \n",
      "diam_pa130_pb433_xa50_ep71.txt sorted... \n",
      "diam_pa130_pb433_xa70_ep71.txt sorted... \n",
      "diam_pa140_pb466_xa30_ep76.txt sorted... \n",
      "diam_pa140_pb466_xa50_ep76.txt sorted... \n",
      "diam_pa140_pb466_xa70_ep76.txt sorted... \n",
      "diam_pa150_pb500_xa30_ep82.txt sorted... \n",
      "diam_pa150_pb500_xa50_ep82.txt sorted... \n",
      "diam_pa150_pb500_xa70_ep82.txt sorted... \n",
      "diam_pa200_pb500_xa50_ep82.txt sorted... \n",
      "diam_pa10_pb20_xa30_ep5.txt sorted... \n",
      "diam_pa10_pb20_xa50_ep5.txt sorted... \n",
      "diam_pa10_pb20_xa70_ep5.txt sorted... \n",
      "diam_pa20_pb40_xa30_ep8.txt sorted... \n",
      "diam_pa20_pb40_xa50_ep8.txt sorted... \n",
      "diam_pa20_pb40_xa70_ep8.txt sorted... \n",
      "diam_pa30_pb60_xa30_ep11.txt sorted... \n",
      "diam_pa30_pb60_xa50_ep11.txt sorted... \n",
      "diam_pa30_pb60_xa70_ep11.txt sorted... \n",
      "diam_pa40_pb80_xa30_ep14.txt sorted... \n",
      "diam_pa40_pb80_xa50_ep14.txt sorted... \n",
      "diam_pa40_pb80_xa70_ep14.txt sorted... \n",
      "diam_pa50_pb100_xa30_ep18.txt sorted... \n",
      "diam_pa50_pb100_xa50_ep18.txt sorted... \n",
      "diam_pa50_pb100_xa70_ep18.txt sorted... \n",
      "diam_pa60_pb120_xa30_ep21.txt sorted... \n",
      "diam_pa60_pb120_xa50_ep21.txt sorted... \n",
      "diam_pa60_pb120_xa70_ep21.txt sorted... \n",
      "diam_pa70_pb140_xa30_ep24.txt sorted... \n",
      "diam_pa70_pb140_xa50_ep24.txt sorted... \n",
      "diam_pa70_pb140_xa70_ep24.txt sorted... \n",
      "diam_pa80_pb160_xa30_ep27.txt sorted... \n",
      "diam_pa80_pb160_xa50_ep27.txt sorted... \n",
      "diam_pa80_pb160_xa70_ep27.txt sorted... \n",
      "diam_pa90_pb180_xa30_ep30.txt sorted... \n",
      "diam_pa90_pb180_xa50_ep30.txt sorted... \n",
      "diam_pa90_pb180_xa70_ep30.txt sorted... \n",
      "diam_pa100_pb200_xa30_ep34.txt sorted... \n",
      "diam_pa100_pb200_xa50_ep34.txt sorted... \n",
      "diam_pa100_pb200_xa70_ep34.txt sorted... \n",
      "diam_pa110_pb220_xa30_ep37.txt sorted... \n",
      "diam_pa110_pb220_xa50_ep37.txt sorted... \n",
      "diam_pa110_pb220_xa70_ep37.txt sorted... \n",
      "diam_pa120_pb240_xa30_ep40.txt sorted... \n",
      "diam_pa120_pb240_xa50_ep40.txt sorted... \n",
      "diam_pa120_pb240_xa70_ep40.txt sorted... \n",
      "diam_pa130_pb260_xa30_ep43.txt sorted... \n",
      "diam_pa130_pb260_xa50_ep43.txt sorted... \n",
      "diam_pa130_pb260_xa70_ep43.txt sorted... \n",
      "diam_pa140_pb280_xa30_ep46.txt sorted... \n",
      "diam_pa140_pb280_xa50_ep46.txt sorted... \n",
      "diam_pa140_pb280_xa70_ep46.txt sorted... \n",
      "diam_pa150_pb300_xa30_ep50.txt sorted... \n",
      "diam_pa150_pb300_xa50_ep50.txt sorted... \n",
      "diam_pa150_pb300_xa70_ep50.txt sorted... \n",
      "diam_pa250_pb500_xa10_ep82.txt sorted... \n",
      "diam_pa250_pb500_xa20_ep82.txt sorted... \n",
      "diam_pa250_pb500_xa30_ep82.txt sorted... \n",
      "diam_pa250_pb500_xa40_ep82.txt sorted... \n",
      "diam_pa250_pb500_xa50_ep82.txt sorted... \n",
      "diam_pa250_pb500_xa60_ep82.txt sorted... \n",
      "diam_pa250_pb500_xa70_ep82.txt sorted... \n",
      "diam_pa250_pb500_xa80_ep82.txt sorted... \n",
      "diam_pa250_pb500_xa90_ep82.txt sorted... \n",
      "diam_pa300_pb500_xa50_ep82.txt sorted... \n",
      "diam_pa10_pb14_xa30_ep4.txt sorted... \n",
      "diam_pa10_pb14_xa50_ep4.txt sorted... \n",
      "diam_pa10_pb14_xa70_ep4.txt sorted... \n",
      "diam_pa20_pb28_xa30_ep6.txt sorted... \n",
      "diam_pa20_pb28_xa50_ep6.txt sorted... \n",
      "diam_pa20_pb28_xa70_ep6.txt sorted... \n",
      "diam_pa30_pb42_xa30_ep8.txt sorted... \n",
      "diam_pa30_pb42_xa50_ep8.txt sorted... \n",
      "diam_pa30_pb42_xa70_ep8.txt sorted... \n",
      "diam_pa40_pb57_xa30_ep11.txt sorted... \n",
      "diam_pa40_pb57_xa50_ep11.txt sorted... \n",
      "diam_pa40_pb57_xa70_ep11.txt sorted... \n",
      "diam_pa50_pb71_xa30_ep13.txt sorted... \n",
      "diam_pa50_pb71_xa50_ep13.txt sorted... \n",
      "diam_pa50_pb71_xa70_ep13.txt sorted... \n",
      "diam_pa60_pb85_xa30_ep15.txt sorted... \n",
      "diam_pa60_pb85_xa50_ep15.txt sorted... \n",
      "diam_pa60_pb85_xa70_ep15.txt sorted... \n",
      "diam_pa70_pb100_xa30_ep18.txt sorted... \n",
      "diam_pa70_pb100_xa50_ep18.txt sorted... \n",
      "diam_pa70_pb100_xa70_ep18.txt sorted... \n",
      "diam_pa80_pb114_xa30_ep20.txt sorted... \n",
      "diam_pa80_pb114_xa50_ep20.txt sorted... \n",
      "diam_pa80_pb114_xa70_ep20.txt sorted... \n",
      "diam_pa90_pb128_xa30_ep22.txt sorted... \n",
      "diam_pa90_pb128_xa50_ep22.txt sorted... \n",
      "diam_pa90_pb128_xa70_ep22.txt sorted... \n",
      "diam_pa100_pb142_xa30_ep24.txt sorted... \n",
      "diam_pa100_pb142_xa50_ep24.txt sorted... \n",
      "diam_pa100_pb142_xa70_ep24.txt sorted... \n",
      "diam_pa110_pb157_xa30_ep27.txt sorted... \n",
      "diam_pa110_pb157_xa50_ep27.txt sorted... \n",
      "diam_pa110_pb157_xa70_ep27.txt sorted... \n",
      "diam_pa120_pb171_xa30_ep29.txt sorted... \n",
      "diam_pa120_pb171_xa50_ep29.txt sorted... \n",
      "diam_pa120_pb171_xa70_ep29.txt sorted... \n",
      "diam_pa130_pb185_xa30_ep31.txt sorted... \n",
      "diam_pa130_pb185_xa50_ep31.txt sorted... \n",
      "diam_pa130_pb185_xa70_ep31.txt sorted... \n",
      "diam_pa140_pb200_xa30_ep34.txt sorted... \n",
      "diam_pa140_pb200_xa50_ep34.txt sorted... \n",
      "diam_pa140_pb200_xa70_ep34.txt sorted... \n",
      "diam_pa150_pb214_xa30_ep36.txt sorted... \n",
      "diam_pa150_pb214_xa50_ep36.txt sorted... \n",
      "diam_pa150_pb214_xa70_ep36.txt sorted... \n",
      "diam_pa350_pb500_xa50_ep82.txt sorted... \n",
      "diam_pa375_pb500_xa10_ep82.txt sorted... \n",
      "diam_pa375_pb500_xa20_ep82.txt sorted... \n",
      "diam_pa375_pb500_xa30_ep82.txt sorted... \n",
      "diam_pa375_pb500_xa40_ep82.txt sorted... \n",
      "diam_pa375_pb500_xa50_ep82.txt sorted... \n",
      "diam_pa375_pb500_xa60_ep82.txt sorted... \n",
      "diam_pa375_pb500_xa70_ep82.txt sorted... \n",
      "diam_pa375_pb500_xa80_ep82.txt sorted... \n",
      "diam_pa375_pb500_xa90_ep82.txt sorted... \n",
      "diam_pa375_pb500_xa100_ep82.txt sorted... \n",
      "diam_pa400_pb500_xa50_ep82.txt sorted... \n",
      "diam_pa10_pb11_xa50_ep3.txt sorted... \n",
      "diam_pa20_pb22_xa50_ep5.txt sorted... \n",
      "diam_pa30_pb33_xa50_ep7.txt sorted... \n",
      "diam_pa40_pb44_xa50_ep9.txt sorted... \n",
      "diam_pa50_pb55_xa50_ep10.txt sorted... \n",
      "diam_pa60_pb66_xa50_ep12.txt sorted... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diam_pa70_pb77_xa50_ep14.txt sorted... \n",
      "diam_pa80_pb88_xa50_ep16.txt sorted... \n",
      "diam_pa90_pb100_xa50_ep18.txt sorted... \n",
      "diam_pa100_pb111_xa50_ep19.txt sorted... \n",
      "diam_pa110_pb122_xa50_ep21.txt sorted... \n",
      "diam_pa120_pb133_xa50_ep23.txt sorted... \n",
      "diam_pa130_pb144_xa50_ep25.txt sorted... \n",
      "diam_pa140_pb155_xa50_ep26.txt sorted... \n",
      "diam_pa150_pb166_xa50_ep28.txt sorted... \n",
      "diam_pa450_pb500_xa50_ep82.txt sorted... \n",
      "diam_pa500_pb500_xa50_ep82.txt sorted... \n"
     ]
    }
   ],
   "source": [
    "# Make sure all data is chronilogical\n",
    "def chkSort(array):\n",
    "    \"\"\"Make sure array is chronilogical\"\"\"\n",
    "    for i in xrange(len(array)-2):\n",
    "        if array[i] > array[i+1]:\n",
    "            print(\"{} is not greater than {} for indices=({},{})\").format(array[i+1], array[i], i, i+1)\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Check to see if timesteps are in order\n",
    "for i in xrange(numFiles):\n",
    "    myBool = chkSort(all_sims[i]['Timestep'])\n",
    "    if myBool is False:\n",
    "        print(\"{} is not chronilogically sorted!\").format(txtFiles[i])\n",
    "        exit(1)\n",
    "    else:\n",
    "        print(\"{} sorted... \").format(txtFiles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add a column to the all_sims dataframe for number of clusters (of threshold size):\n",
    "for i in xrange(numFiles):\n",
    "    # New column for number of clusters\n",
    "    all_sims[i]['nClust'] = all_sims[i]['Dense_tot'] / all_sims[i]['MCS']\n",
    "    # Ger rid of NaN in favor of 0\n",
    "    all_sims[i].fillna(0, inplace=True)\n",
    "\n",
    "# display(all_sims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that will sort wrt one variable\n",
    "def singleSort(arr):\n",
    "    for i in xrange(len(arr)):\n",
    "        for j in xrange(len(arr)):\n",
    "            if arr[i] < arr[j] and i > j:\n",
    "                arr[i], arr[j] = arr[j], arr[i]\n",
    "                \n",
    "# Function to get conversion from timesteps to Brownian time\n",
    "def computeTauPerTstep(epsilon):\n",
    "    # This is actually indpendent of runtime :)\n",
    "    sigma = 1.0\n",
    "    threeEtaPiSigma = 1.0\n",
    "    runFor = 200\n",
    "    tauBrown = 1.0\n",
    "    \n",
    "    tauLJ = ((sigma**2) * threeEtaPiSigma) / epsilon\n",
    "    dt = 0.00001 * tauLJ\n",
    "    simLength = runFor * tauBrown\n",
    "    totTsteps = int(simLength / dt)\n",
    "    tstepPerTau = int(totTsteps / float(simLength))\n",
    "    return tstepPerTau\n",
    "\n",
    "def theoryDenom(xS, peS, peF):\n",
    "    xS /= 100.0\n",
    "    xF = 1.0 - xS\n",
    "    return 4.0 * ((xS * peS) + (xF * peF))\n",
    "\n",
    "# Make an additional frame that gives total number of particles, and simulation parameters\n",
    "paramList = []\n",
    "for i in xrange(numFiles):\n",
    "    partAll = all_sims[i]['Gas_tot'][0]\n",
    "    partA = all_sims[i]['Gas_A'][0]\n",
    "    partB = all_sims[i]['Gas_B'][0]\n",
    "    pa = getFromTxt(txtFiles[i], \"pa\", \"_pb\")\n",
    "    pb = getFromTxt(txtFiles[i], \"pb\", \"_xa\")\n",
    "    xa = getFromTxt(txtFiles[i], \"xa\", \"_ep\")\n",
    "    ep = getFromTxt(txtFiles[i], \"ep\", \".txt\")\n",
    "    converT = computeTauPerTstep(ep)\n",
    "    theory = theoryDenom(xa, pa, pb)\n",
    "    \n",
    "    try:\n",
    "        # Round to the nearest tenths place\n",
    "        prat = round(float(pa)/float(pb) * 2, 1) / 2\n",
    "    except:\n",
    "        prat = 0.0\n",
    "    paramList.append((partAll, partA, partB, pa, pb, xa, prat, ep, converT, theory))\n",
    "\n",
    "params = pd.DataFrame(paramList, columns=['partAll', 'partA', 'partB', 'peA', 'peB', 'xA', 'peR', 'eps', 'brownTime', 'theory'])\n",
    "# display(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "112",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-734411a347d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Get indices for files which aren't at steady-state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumFiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mall_sims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Timestep'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'brownTime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mssStartTime\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_sims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Timestep'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mall_sims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Timestep'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'brownTime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mssStartTime\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   3116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3117\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 3118\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   3119\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 112"
     ]
    }
   ],
   "source": [
    "# Figure out how what we should use for steady-state\n",
    "numFiles = len(txtFiles)\n",
    "# We should average past a specific time, not an index number...\n",
    "ssStartTime = 25.0\n",
    "ssStartInd = []\n",
    "badFiles = []\n",
    "# Get indices for files which aren't at steady-state\n",
    "for i in xrange(numFiles):\n",
    "    if all_sims[i]['Timestep'].iloc[-1] / params['brownTime'][i] >= ssStartTime:\n",
    "        for j in xrange(len(all_sims[i]['Timestep'])):\n",
    "            if all_sims[i]['Timestep'][j] / params['brownTime'][i] >= ssStartTime:\n",
    "                ssStartInd.append(j)\n",
    "    else:\n",
    "        badFiles.append(i)\n",
    "\n",
    "# Make sure files have correct number of columns:\n",
    "for i in xrange(numFiles):\n",
    "    if len(all_sims[i].iloc[1]) != 22:\n",
    "        print(\"ERROR: {}\").format(txtFiles[i])\n",
    "        badFiles.append(i)\n",
    "\n",
    "# Remove these indices from: txtFiles, all_sims, params\n",
    "print(\"Number of textfiles before delete: {}\").format(len(txtFiles))\n",
    "print(\"Number of all_sims dataframes before delete: {}\").format(len(all_sims))\n",
    "print(\"Params rows before delete: {}\").format(len(params['partAll']))\n",
    "if badFiles:\n",
    "    for i in xrange(len(badFiles)):\n",
    "        del txtFiles[badFiles[i]]\n",
    "        del all_sims[badFiles[i]]\n",
    "    params.drop(badFiles, axis=0, inplace=True)\n",
    "print(\"Number of textfiles after delete: {}\").format(len(txtFiles))\n",
    "print(\"Number of all_sims dataframes after delete: {}\").format(len(all_sims))\n",
    "print(\"Params rows after delete: {}\").format(len(params['partAll']))\n",
    "\n",
    "numFiles = len(txtFiles)\n",
    "del badFiles[:]\n",
    "\n",
    "# Visual check to see if this is the appropriate time window for steady-state\n",
    "for i in xrange(numFiles):\n",
    "    plt.plot(all_sims[i]['Timestep'][:] / params['brownTime'][i],\n",
    "             all_sims[i]['Dense_A'][:] / params['partA'][i] * 100.0,\n",
    "             c='b',\n",
    "             label=str(params['peR'][i]))\n",
    "    plt.plot(all_sims[i]['Timestep'][ssStartInd[i]:-1] / params['brownTime'][i],\n",
    "             all_sims[i]['Dense_A'][ssStartInd[i]:-1] / params['partA'][i] * 100.0,\n",
    "             c='k')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lists for distinct values that I might want to plot\n",
    "distPeR = []\n",
    "for i in xrange(numFiles):\n",
    "    if params['peR'][i] not in distPeR:\n",
    "        distPeR.append(params['peR'][i])\n",
    "singleSort(distPeR)\n",
    "print(distPeR)\n",
    "\n",
    "distxA = []\n",
    "for i in xrange(numFiles):\n",
    "    if params['xA'][i] not in distxA:\n",
    "        distxA.append(params['xA'][i])\n",
    "singleSort(distxA)\n",
    "print(distxA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get time-based steady state values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out how what we should use for steady-state\n",
    "\n",
    "# How many frames to average over for steady-state\n",
    "avgOver = 50\n",
    "\n",
    "# Make list of steady state column headers\n",
    "headers = list(all_sims[0])\n",
    "headers.remove('Timestep')\n",
    "SS = pd.DataFrame(columns=headers)\n",
    "stdErr = pd.DataFrame(columns=headers)\n",
    "var = pd.DataFrame(columns=headers)\n",
    "for i in xrange(numFiles):\n",
    "    SS.loc[i] = [0] * len(headers)\n",
    "    stdErr.loc[i] = [0] * len(headers)\n",
    "    var.loc[i] = [0] * len(headers)\n",
    "\n",
    "# Make dataframe of steady-state data\n",
    "for i in xrange(numFiles):\n",
    "    # Loop through each column (aside from tstep column)\n",
    "    for j in range(1, len(all_sims[i].iloc[1])):\n",
    "        # Compute mean of last avgOver entries in jth column of ith file\n",
    "        avg = np.mean(all_sims[i].iloc[-avgOver:-1,j])\n",
    "        SS[headers[j-1]][i] = avg\n",
    "        # Compute the standard deviation and variance in this data\n",
    "        stdError = np.std(all_sims[i].iloc[-avgOver:-1,j])\n",
    "        stdErr[headers[j-1]][i] = stdError\n",
    "        var[headers[j-1]][i] = stdError ** 2\n",
    "        \n",
    "# Normalize by number of particles\n",
    "for i in xrange(len(txtFiles)):\n",
    "    if params['partA'][i] != 0:\n",
    "        SS['Gas_A'][i] /= params['partA'][i]\n",
    "        SS['Dense_A'][i] /= params['partA'][i]\n",
    "        SS['Lc_numA'][i] /= params['partA'][i]\n",
    "        # Now my standard error is a percentage\n",
    "        stdErr['Gas_A'][i] /= params['partA'][i]\n",
    "        stdErr['Dense_A'][i] /= params['partA'][i]\n",
    "        stdErr['Lc_numA'][i] /= params['partA'][i]\n",
    "        var['Gas_A'][i] /= params['partA'][i]\n",
    "        var['Dense_A'][i] /= params['partA'][i]\n",
    "        var['Lc_numA'][i] /= params['partA'][i]\n",
    "        \n",
    "    if params['partB'][i] != 0:\n",
    "        SS['Gas_B'][i] /= params['partB'][i]\n",
    "        SS['Dense_B'][i] /= params['partB'][i]\n",
    "        SS['Lc_numB'][i] /= params['partB'][i]\n",
    "        stdErr['Gas_B'][i] /= params['partB'][i]\n",
    "        stdErr['Dense_B'][i] /= params['partB'][i]\n",
    "        stdErr['Lc_numB'][i] /= params['partB'][i]\n",
    "        var['Gas_B'][i] /= params['partB'][i]\n",
    "        var['Dense_B'][i] /= params['partB'][i]\n",
    "        var['Lc_numB'][i] /= params['partB'][i]\n",
    "\n",
    "SS['Gas_tot'][:] /= params['partAll'][:]\n",
    "SS['Dense_tot'][:] /= params['partAll'][:] \n",
    "SS['Lg_clust'][:] /= params['partAll'][:] \n",
    "SS['MCS'][:] /= params['partAll'][:]\n",
    "stdErr['Gas_tot'][:] /= params['partAll'][:]\n",
    "stdErr['Dense_tot'][:] /= params['partAll'][:] \n",
    "stdErr['Lg_clust'][:] /= params['partAll'][:] \n",
    "stdErr['MCS'][:] /= params['partAll'][:]\n",
    "var['Gas_tot'][:] /= params['partAll'][:]\n",
    "var['Dense_tot'][:] /= params['partAll'][:] \n",
    "var['Lg_clust'][:] /= params['partAll'][:] \n",
    "var['MCS'][:] /= params['partAll'][:]\n",
    "\n",
    "SS['Gas_A'][:] *= 100.0\n",
    "SS['Gas_B'][:] *= 100.0\n",
    "SS['Gas_tot'][:] *= 100.0\n",
    "SS['Dense_A'][:] *= 100.0\n",
    "SS['Dense_B'][:] *= 100.0\n",
    "SS['Dense_tot'][:] *= 100.0\n",
    "SS['Lc_numA'][:] *= 100.0\n",
    "SS['Lc_numB'][:] *= 100.0\n",
    "SS['Lg_clust'][:] *= 100.0\n",
    "SS['MCS'][:] *= 100.0\n",
    "stdErr['Gas_A'][:] *= 100.0\n",
    "stdErr['Gas_B'][:] *= 100.0\n",
    "stdErr['Gas_tot'][:] *= 100.0\n",
    "stdErr['Dense_A'][:] *= 100.0\n",
    "stdErr['Dense_B'][:] *= 100.0\n",
    "stdErr['Dense_tot'][:] *= 100.0\n",
    "stdErr['Lc_numA'][:] *= 100.0\n",
    "stdErr['Lc_numB'][:] *= 100.0\n",
    "stdErr['Lg_clust'][:] *= 100.0\n",
    "stdErr['MCS'][:] *= 100.0\n",
    "var['Gas_A'][:] *= 100.0\n",
    "var['Gas_B'][:] *= 100.0\n",
    "var['Gas_tot'][:] *= 100.0\n",
    "var['Dense_A'][:] *= 100.0\n",
    "var['Dense_B'][:] *= 100.0\n",
    "var['Dense_tot'][:] *= 100.0\n",
    "var['Lc_numA'][:] *= 100.0\n",
    "var['Lc_numB'][:] *= 100.0\n",
    "var['Lg_clust'][:] *= 100.0\n",
    "var['MCS'][:] *= 100.0\n",
    "pd.set_option('display.max_rows', 2)\n",
    "display(SS)\n",
    "display(stdErr)\n",
    "display(var)\n",
    "\n",
    "# Get an idea for what section of the data we are averaging over\n",
    "for i in xrange(numFiles):\n",
    "    plt.plot(all_sims[i]['Timestep'][:] / params['brownTime'][i],\n",
    "             all_sims[i]['Dense_A'][:] / params['partA'][i] * 100.0,\n",
    "             c='b',\n",
    "             label=str(params['peR'][i]))\n",
    "    plt.plot(all_sims[i]['Timestep'][-avgOver:-1] / params['brownTime'][i],\n",
    "             all_sims[i]['Dense_A'][-avgOver:-1] / params['partA'][i] * 100.0,\n",
    "             c='k')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
